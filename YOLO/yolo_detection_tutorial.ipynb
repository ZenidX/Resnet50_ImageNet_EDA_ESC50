{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Video Detection con Supervision\n",
    "\n",
    "## Â¿QuÃ© es YOLO?\n",
    "\n",
    "**YOLO** (You Only Look Once) es una familia de modelos de deep learning para **detecciÃ³n de objetos en tiempo real**.\n",
    "\n",
    "A diferencia de otros detectores que analizan la imagen en mÃºltiples pasadas, YOLO procesa toda la imagen en una sola pasada de la red neuronal, lo que lo hace extremadamente rÃ¡pido.\n",
    "\n",
    "### Versiones de YOLO\n",
    "\n",
    "| VersiÃ³n | AÃ±o | CaracterÃ­sticas |\n",
    "|---------|-----|----------------|\n",
    "| YOLOv8 | 2023 | Arquitectura mejorada, fÃ¡cil de usar |\n",
    "| YOLOv9 | 2024 | Programmable Gradient Information (PGI) |\n",
    "| YOLOv10 | 2024 | Entrenamiento sin NMS (Non-Maximum Suppression) |\n",
    "| YOLO11 | 2024 | Ãšltima versiÃ³n, mejor balance velocidad/precisiÃ³n |\n",
    "\n",
    "## Â¿QuÃ© es Supervision?\n",
    "\n",
    "**Supervision** es una librerÃ­a de Roboflow que facilita:\n",
    "- Convertir resultados de diferentes modelos a un formato unificado\n",
    "- Tracking de objetos (seguimiento entre frames)\n",
    "- Anotaciones visuales (dibujar boxes, etiquetas, trazas)\n",
    "- Procesamiento de video\n",
    "\n",
    "## Objetivo del Notebook\n",
    "\n",
    "Aprenderemos a:\n",
    "1. Cargar un modelo YOLO y detectar objetos\n",
    "2. Usar tracking para seguir objetos entre frames\n",
    "3. Visualizar resultados con anotaciones\n",
    "4. Procesar videos completos y webcam en tiempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. InstalaciÃ³n e Imports\n",
    "\n",
    "### LibrerÃ­as necesarias\n",
    "\n",
    "| LibrerÃ­a | PropÃ³sito |\n",
    "|----------|----------|\n",
    "| `ultralytics` | Modelos YOLO oficiales |\n",
    "| `supervision` | Tracking y anotaciones |\n",
    "| `opencv-python` | ManipulaciÃ³n de imÃ¡genes/video |\n",
    "| `numpy` | Operaciones con arrays |\n",
    "| `matplotlib` | VisualizaciÃ³n en notebooks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INSTALACIÃ“N (ejecutar solo la primera vez)\n",
    "# ============================================================\n",
    "# Descomenta la siguiente lÃ­nea si no tienes las librerÃ­as:\n",
    "# !pip install ultralytics supervision opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "# OpenCV: lectura/escritura de imÃ¡genes y video\n",
    "import cv2\n",
    "\n",
    "# NumPy: los frames son arrays de numpy (altura x anchura x 3 canales BGR)\n",
    "import numpy as np\n",
    "\n",
    "# Supervision: tracking, anotaciones, procesamiento de video\n",
    "import supervision as sv\n",
    "\n",
    "# Ultralytics: modelos YOLO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Matplotlib: visualizaciÃ³n en el notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar versiones\n",
    "print(f\"âœ“ Supervision version: {sv.__version__}\")\n",
    "print(f\"âœ“ OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Cargar el Modelo YOLO\n",
    "\n",
    "### Â¿CÃ³mo funciona YOLO internamente?\n",
    "\n",
    "```\n",
    "Imagen (640x640 RGB)\n",
    "        â”‚\n",
    "        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Backbone CNN    â”‚  â† Extrae caracterÃ­sticas (ResNet, CSPNet, etc.)\n",
    "â”‚   (Feature maps)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚\n",
    "        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚      Neck         â”‚  â† Combina caracterÃ­sticas de diferentes escalas (FPN, PANet)\n",
    "â”‚  (Multi-scale)    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚\n",
    "        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚      Head         â”‚  â† Predice boxes, clases y confianza\n",
    "â”‚  (Detection)      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚\n",
    "        â–¼\n",
    "Lista de detecciones: [(x1,y1,x2,y2, clase, confianza), ...]\n",
    "```\n",
    "\n",
    "### TamaÃ±os de modelo disponibles\n",
    "\n",
    "| Modelo | ParÃ¡metros | Velocidad | PrecisiÃ³n (mAP) | Uso recomendado |\n",
    "|--------|------------|-----------|-----------------|------------------|\n",
    "| `yolo11n.pt` | 2.6M | âš¡âš¡âš¡âš¡âš¡ | 39.5% | Tiempo real, edge devices |\n",
    "| `yolo11s.pt` | 9.4M | âš¡âš¡âš¡âš¡ | 47.0% | Balance velocidad/precisiÃ³n |\n",
    "| `yolo11m.pt` | 20.1M | âš¡âš¡âš¡ | 51.5% | Uso general |\n",
    "| `yolo11l.pt` | 25.3M | âš¡âš¡ | 53.4% | Alta precisiÃ³n |\n",
    "| `yolo11x.pt` | 56.9M | âš¡ | 54.7% | MÃ¡xima precisiÃ³n |\n",
    "\n",
    "**mAP** = Mean Average Precision (mÃ©trica estÃ¡ndar de detecciÃ³n, 0-100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARGAR MODELO YOLO\n",
    "# ============================================================\n",
    "# La primera vez se descarga automÃ¡ticamente (~5-50 MB segÃºn el modelo)\n",
    "# Los pesos se guardan en el directorio actual\n",
    "\n",
    "MODEL_NAME = \"yolo11n.pt\"  # Usamos nano para velocidad\n",
    "\n",
    "print(f\"Cargando modelo {MODEL_NAME}...\")\n",
    "model = YOLO(MODEL_NAME)\n",
    "print(f\"âœ“ Modelo cargado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPLORAR LAS CLASES DEL MODELO\n",
    "# ============================================================\n",
    "# YOLO viene pre-entrenado en COCO dataset (80 clases comunes)\n",
    "\n",
    "print(f\"El modelo puede detectar {len(model.names)} clases diferentes:\\n\")\n",
    "\n",
    "# Mostrar todas las clases en columnas\n",
    "clases = list(model.names.values())\n",
    "for i in range(0, len(clases), 4):\n",
    "    row = clases[i:i+4]\n",
    "    print(\"  \".join(f\"{i+j:2d}. {c:<15}\" for j, c in enumerate(row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. DetecciÃ³n en una Imagen\n",
    "\n",
    "### El flujo de detecciÃ³n\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚    Imagen    â”‚  â”€â”€â–º â”‚  model(img)  â”‚  â”€â”€â–º â”‚  Results object      â”‚\n",
    "â”‚  (np.array)  â”‚      â”‚              â”‚      â”‚  - boxes (xyxy)      â”‚\n",
    "â”‚  BGR format  â”‚      â”‚              â”‚      â”‚  - confidence scores â”‚\n",
    "â”‚              â”‚      â”‚              â”‚      â”‚  - class IDs         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Formato de Bounding Box: xyxy\n",
    "\n",
    "```\n",
    "    x1 (left)\n",
    "    â”‚\n",
    "    â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â—„â”€â”€ y1 (top)\n",
    "    â”‚                 â”‚\n",
    "    â”‚     OBJETO      â”‚\n",
    "    â”‚                 â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â—„â”€â”€ y2 (bottom)\n",
    "                      â–²\n",
    "                      â”‚\n",
    "                   x2 (right)\n",
    "\n",
    "xyxy = [x1, y1, x2, y2] = [left, top, right, bottom]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CAPTURAR IMAGEN DE LA WEBCAM\n",
    "# ============================================================\n",
    "# cv2.VideoCapture(0) abre la webcam por defecto\n",
    "# TambiÃ©n podrÃ­as cargar una imagen: frame = cv2.imread(\"imagen.jpg\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 0 = webcam por defecto\n",
    "ret, frame = cap.read()     # ret = True si se capturÃ³ correctamente\n",
    "cap.release()               # Liberar la webcam\n",
    "\n",
    "if ret:\n",
    "    print(f\"âœ“ Imagen capturada: {frame.shape}\")\n",
    "    print(f\"  - Altura: {frame.shape[0]} pÃ­xeles\")\n",
    "    print(f\"  - Anchura: {frame.shape[1]} pÃ­xeles\") \n",
    "    print(f\"  - Canales: {frame.shape[2]} (BGR)\")\n",
    "    \n",
    "    # Mostrar imagen (convertir BGR->RGB para matplotlib)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Imagen original de la webcam\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No se pudo capturar imagen de la webcam\")\n",
    "    print(\"   Creando imagen de prueba...\")\n",
    "    frame = np.zeros((480, 640, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar la detecciÃ³n\n",
    "\n",
    "El parÃ¡metro `conf` es el **umbral de confianza**:\n",
    "- `conf=0.5` â†’ Solo detecciones con >50% de confianza\n",
    "- Valor alto (0.7-0.9) â†’ Menos detecciones, mÃ¡s precisas\n",
    "- Valor bajo (0.1-0.3) â†’ MÃ¡s detecciones, incluye falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EJECUTAR DETECCIÃ“N YOLO\n",
    "# ============================================================\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.5  # 50% mÃ­nimo de confianza\n",
    "\n",
    "# model() devuelve una lista de Results (uno por imagen)\n",
    "# Como pasamos una sola imagen, tomamos el primer elemento [0]\n",
    "results = model(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)[0]\n",
    "\n",
    "print(f\"Inferencia completada\")\n",
    "print(f\"  - Objetos detectados: {len(results.boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir a formato Supervision\n",
    "\n",
    "**Â¿Por quÃ© usar `sv.Detections`?**\n",
    "\n",
    "Supervision proporciona una clase unificada que funciona con cualquier detector:\n",
    "- `sv.Detections.from_ultralytics()` - Para YOLO\n",
    "- `sv.Detections.from_detectron2()` - Para Detectron2\n",
    "- `sv.Detections.from_transformers()` - Para HuggingFace\n",
    "\n",
    "Esto permite usar el mismo cÃ³digo de anotaciÃ³n/tracking independientemente del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONVERTIR A FORMATO SUPERVISION\n",
    "# ============================================================\n",
    "\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "# Explorar la estructura de Detections\n",
    "print(\"Estructura de sv.Detections:\")\n",
    "print(f\"  - xyxy: array de bounding boxes [{len(detections)}x4]\")\n",
    "print(f\"  - confidence: array de confianzas [{len(detections)}]\")\n",
    "print(f\"  - class_id: array de IDs de clase [{len(detections)}]\")\n",
    "print(f\"  - tracker_id: {detections.tracker_id} (None hasta aplicar tracking)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DETECCIONES ENCONTRADAS: {len(detections)}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for i, (xyxy, conf, class_id) in enumerate(zip(\n",
    "    detections.xyxy, \n",
    "    detections.confidence, \n",
    "    detections.class_id\n",
    ")):\n",
    "    class_name = model.names[class_id]\n",
    "    x1, y1, x2, y2 = xyxy.astype(int)\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    \n",
    "    print(f\"\\n{i+1}. {class_name.upper()}\")\n",
    "    print(f\"   Confianza: {conf:.1%}\")\n",
    "    print(f\"   Bounding box: ({x1}, {y1}) â†’ ({x2}, {y2})\")\n",
    "    print(f\"   TamaÃ±o: {width}x{height} pÃ­xeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar con Annotators\n",
    "\n",
    "**Annotators disponibles en Supervision:**\n",
    "\n",
    "| Annotator | DescripciÃ³n |\n",
    "|-----------|-------------|\n",
    "| `BoxAnnotator` | Dibuja rectÃ¡ngulos alrededor de objetos |\n",
    "| `LabelAnnotator` | AÃ±ade texto (clase, confianza, ID) |\n",
    "| `MaskAnnotator` | Rellena el Ã¡rea del objeto (segmentaciÃ³n) |\n",
    "| `TraceAnnotator` | Dibuja la trayectoria histÃ³rica |\n",
    "| `HeatMapAnnotator` | Mapa de calor de actividad |\n",
    "| `CircleAnnotator` | CÃ­rculos en lugar de boxes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREAR ANOTADORES\n",
    "# ============================================================\n",
    "\n",
    "# BoxAnnotator: dibuja los rectÃ¡ngulos\n",
    "# - thickness: grosor de la lÃ­nea en pÃ­xeles\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "    thickness=2  # Grosor del borde del rectÃ¡ngulo\n",
    ")\n",
    "\n",
    "# LabelAnnotator: dibuja las etiquetas de texto\n",
    "# - text_scale: tamaÃ±o del texto (0.5 = mitad del default)\n",
    "# - text_thickness: grosor del texto\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    text_scale=0.5,\n",
    "    text_thickness=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENERAR ETIQUETAS PERSONALIZADAS\n",
    "# ============================================================\n",
    "# Creamos una lista de strings para cada detecciÃ³n\n",
    "# Formato: \"clase confianza\" (ej: \"person 0.95\")\n",
    "\n",
    "labels = []\n",
    "for class_id, confidence in zip(detections.class_id, detections.confidence):\n",
    "    class_name = model.names[class_id]  # Convertir ID a nombre\n",
    "    label = f\"{class_name} {confidence:.2f}\"  # ej: \"person 0.95\"\n",
    "    labels.append(label)\n",
    "\n",
    "print(f\"Etiquetas generadas: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANOTAR LA IMAGEN\n",
    "# ============================================================\n",
    "# IMPORTANTE: Siempre trabajar sobre una COPIA del frame\n",
    "# para no modificar el original\n",
    "\n",
    "# Paso 1: Copiar el frame original\n",
    "annotated = frame.copy()\n",
    "\n",
    "# Paso 2: Dibujar bounding boxes\n",
    "annotated = box_annotator.annotate(\n",
    "    scene=annotated,           # Imagen sobre la que dibujar\n",
    "    detections=detections      # Detecciones a dibujar\n",
    ")\n",
    "\n",
    "# Paso 3: Dibujar etiquetas\n",
    "annotated = label_annotator.annotate(\n",
    "    scene=annotated,\n",
    "    detections=detections,\n",
    "    labels=labels              # Lista de strings personalizados\n",
    ")\n",
    "\n",
    "# Visualizar resultado\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"DetecciÃ³n YOLO - {len(detections)} objetos detectados\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Tracking de Objetos con ByteTrack\n",
    "\n",
    "### Â¿QuÃ© es el tracking?\n",
    "\n",
    "**DetecciÃ³n** identifica objetos en cada frame de forma independiente.\n",
    "\n",
    "**Tracking** asocia las detecciones entre frames para saber que \"el objeto en el frame 1\" es \"el mismo objeto en el frame 2\".\n",
    "\n",
    "```\n",
    "Frame 1          Frame 2          Frame 3\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ â”Œâ”€â”€â”€â”   â”‚      â”‚   â”Œâ”€â”€â”€â” â”‚      â”‚     â”Œâ”€â”€â”€â”â”‚\n",
    "â”‚ â”‚ A â”‚   â”‚  â”€â”€â–º â”‚   â”‚ ? â”‚ â”‚  â”€â”€â–º â”‚     â”‚ ? â”‚â”‚\n",
    "â”‚ â””â”€â”€â”€â”˜   â”‚      â”‚   â””â”€â”€â”€â”˜ â”‚      â”‚     â””â”€â”€â”€â”˜â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Sin tracking: A, B, C (diferentes IDs cada frame)\n",
    "Con tracking: A, A, A (mismo ID = mismo objeto)\n",
    "```\n",
    "\n",
    "### Â¿CÃ³mo funciona ByteTrack?\n",
    "\n",
    "1. **AsociaciÃ³n por posiciÃ³n**: Si un objeto estÃ¡ cerca de donde estaba antes, probablemente es el mismo\n",
    "2. **PredicciÃ³n de movimiento**: Usa filtro de Kalman para predecir dÃ³nde estarÃ¡ el objeto\n",
    "3. **Manejo de oclusiones**: Mantiene IDs aunque el objeto desaparezca temporalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREAR TRACKER\n",
    "# ============================================================\n",
    "# ByteTrack es el algoritmo de tracking incluido en supervision\n",
    "# Mantiene un estado interno de los objetos trackeados\n",
    "\n",
    "tracker = sv.ByteTrack(\n",
    "    # ParÃ¡metros opcionales:\n",
    "    # track_activation_threshold=0.25,  # Confianza mÃ­nima para nuevo track\n",
    "    # lost_track_buffer=30,             # Frames antes de eliminar track perdido\n",
    "    # minimum_matching_threshold=0.8,   # Umbral para asociar detecciones\n",
    "    # frame_rate=30                     # FPS del video\n",
    ")\n",
    "\n",
    "print(\"âœ“ Tracker ByteTrack creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# APLICAR TRACKING A LAS DETECCIONES\n",
    "# ============================================================\n",
    "# update_with_detections() hace dos cosas:\n",
    "# 1. Asocia detecciones actuales con tracks existentes\n",
    "# 2. AÃ±ade el campo tracker_id a las detecciones\n",
    "\n",
    "detections_with_tracking = tracker.update_with_detections(detections)\n",
    "\n",
    "print(\"Detecciones CON tracking:\")\n",
    "print(f\"  - tracker_id: {detections_with_tracking.tracker_id}\")\n",
    "\n",
    "if detections_with_tracking.tracker_id is not None:\n",
    "    print(f\"\\nObjetos trackeados:\")\n",
    "    for tid, cid, conf in zip(\n",
    "        detections_with_tracking.tracker_id,\n",
    "        detections_with_tracking.class_id,\n",
    "        detections_with_tracking.confidence\n",
    "    ):\n",
    "        print(f\"  ID #{tid}: {model.names[cid]} ({conf:.1%})\")\n",
    "else:\n",
    "    print(\"  (No hay objetos trackeados)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Procesar Video Completo\n",
    "\n",
    "### Flujo de procesamiento de video\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Video     â”‚     â”‚    Para cada    â”‚     â”‚   Video     â”‚\n",
    "â”‚   entrada   â”‚ â”€â”€â–º â”‚     frame:      â”‚ â”€â”€â–º â”‚   salida    â”‚\n",
    "â”‚  (MP4/AVI)  â”‚     â”‚   callback()    â”‚     â”‚  (MP4/AVI)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â–¼\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚  callback:  â”‚\n",
    "                    â”‚ 1. Detectar â”‚\n",
    "                    â”‚ 2. Trackear â”‚\n",
    "                    â”‚ 3. Anotar   â”‚\n",
    "                    â”‚ 4. Return   â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### sv.process_video()\n",
    "\n",
    "Esta funciÃ³n de supervision:\n",
    "1. Abre el video de entrada\n",
    "2. Lee cada frame\n",
    "3. Llama a tu funciÃ³n `callback(frame, index)`\n",
    "4. Escribe el frame retornado al video de salida\n",
    "5. Cierra los archivos automÃ¡ticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURACIÃ“N DEL PROCESAMIENTO DE VIDEO\n",
    "# ============================================================\n",
    "\n",
    "VIDEO_INPUT = \"test_video.mp4\"     # Video de entrada (cambiar por tu video)\n",
    "VIDEO_OUTPUT = \"output_notebook.mp4\"  # Video de salida\n",
    "CONFIDENCE = 0.5                   # Umbral de confianza\n",
    "\n",
    "# IMPORTANTE: Reiniciar el tracker para cada video nuevo\n",
    "# Si no, los IDs continuarÃ­an del video anterior\n",
    "tracker = sv.ByteTrack()\n",
    "\n",
    "# Crear los tres anotadores que usaremos\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_scale=0.5, text_thickness=1)\n",
    "trace_annotator = sv.TraceAnnotator(\n",
    "    thickness=2,      # Grosor de la lÃ­nea de traza\n",
    "    trace_length=50   # CuÃ¡ntos frames de historia mostrar\n",
    ")\n",
    "\n",
    "print(\"âœ“ ConfiguraciÃ³n lista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEFINIR LA FUNCIÃ“N CALLBACK\n",
    "# ============================================================\n",
    "# Esta funciÃ³n se ejecutarÃ¡ para CADA frame del video\n",
    "# Debe recibir (frame, frame_idx) y devolver el frame anotado\n",
    "\n",
    "def process_frame(frame: np.ndarray, frame_idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procesa un frame individual del video.\n",
    "    \n",
    "    Args:\n",
    "        frame: Imagen BGR del frame actual (numpy array)\n",
    "        frame_idx: Ãndice del frame (0, 1, 2, ...)\n",
    "    \n",
    "    Returns:\n",
    "        Frame anotado con detecciones, tracking y trazas\n",
    "    \"\"\"\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PASO 1: DETECCIÃ“N YOLO\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # verbose=False evita que imprima info en cada frame\n",
    "    results = model(frame, conf=CONFIDENCE, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PASO 2: TRACKING\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Asocia detecciones con IDs persistentes\n",
    "    detections = tracker.update_with_detections(detections)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PASO 3: GENERAR ETIQUETAS\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Formato: \"#ID clase confianza\" (ej: \"#1 person 0.95\")\n",
    "    if detections.tracker_id is not None:\n",
    "        labels = [\n",
    "            f\"#{tid} {model.names[cid]} {conf:.2f}\"\n",
    "            for tid, cid, conf in zip(\n",
    "                detections.tracker_id,\n",
    "                detections.class_id,\n",
    "                detections.confidence\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        labels = [\n",
    "            f\"{model.names[cid]} {conf:.2f}\"\n",
    "            for cid, conf in zip(detections.class_id, detections.confidence)\n",
    "        ]\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # PASO 4: ANOTAR FRAME\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Orden importante: primero traces (fondo), luego boxes, luego labels\n",
    "    annotated = frame.copy()\n",
    "    annotated = trace_annotator.annotate(annotated, detections=detections)  # Trazas\n",
    "    annotated = box_annotator.annotate(annotated, detections=detections)    # Boxes\n",
    "    annotated = label_annotator.annotate(annotated, detections=detections, labels=labels)  # Labels\n",
    "    \n",
    "    # Mostrar progreso cada 50 frames\n",
    "    if frame_idx % 50 == 0:\n",
    "        print(f\"  Frame {frame_idx}: {len(detections)} objetos detectados\")\n",
    "    \n",
    "    return annotated\n",
    "\n",
    "print(\"âœ“ FunciÃ³n callback definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFICAR VIDEO DE ENTRADA\n",
    "# ============================================================\n",
    "import os\n",
    "\n",
    "if os.path.exists(VIDEO_INPUT):\n",
    "    # sv.VideoInfo extrae metadatos del video\n",
    "    video_info = sv.VideoInfo.from_video_path(VIDEO_INPUT)\n",
    "    \n",
    "    print(f\"ğŸ“¹ Video de entrada: {VIDEO_INPUT}\")\n",
    "    print(f\"   â”œâ”€â”€ ResoluciÃ³n: {video_info.width} x {video_info.height}\")\n",
    "    print(f\"   â”œâ”€â”€ FPS: {video_info.fps}\")\n",
    "    print(f\"   â”œâ”€â”€ Total frames: {video_info.total_frames}\")\n",
    "    print(f\"   â””â”€â”€ DuraciÃ³n: {video_info.total_frames / video_info.fps:.1f} segundos\")\n",
    "else:\n",
    "    print(f\"âš ï¸ No se encontrÃ³ el video: {VIDEO_INPUT}\")\n",
    "    print(f\"   Opciones:\")\n",
    "    print(f\"   1. Descarga un video de prueba\")\n",
    "    print(f\"   2. Cambia VIDEO_INPUT a la ruta de tu video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PROCESAR EL VIDEO\n",
    "# ============================================================\n",
    "# sv.process_video() se encarga de:\n",
    "# - Abrir el video de entrada\n",
    "# - Leer frame por frame\n",
    "# - Llamar a callback(frame, idx) para cada frame\n",
    "# - Escribir el resultado al video de salida\n",
    "# - Cerrar los archivos\n",
    "\n",
    "if os.path.exists(VIDEO_INPUT):\n",
    "    print(f\"\\nğŸ”„ Procesando video...\\n\")\n",
    "    \n",
    "    sv.process_video(\n",
    "        source_path=VIDEO_INPUT,   # Video original\n",
    "        target_path=VIDEO_OUTPUT,  # Video con anotaciones\n",
    "        callback=process_frame     # Nuestra funciÃ³n\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Video guardado en: {VIDEO_OUTPUT}\")\n",
    "    print(f\"   TamaÃ±o: {os.path.getsize(VIDEO_OUTPUT) / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. DetecciÃ³n en Tiempo Real (Webcam)\n",
    "\n",
    "### Diferencia con procesamiento de archivo\n",
    "\n",
    "| Aspecto | Archivo | Webcam |\n",
    "|---------|---------|--------|\n",
    "| Fuente | `sv.process_video()` | `cv2.VideoCapture(0)` |\n",
    "| Velocidad | Procesa lo mÃ¡s rÃ¡pido posible | Limitado por FPS de la cÃ¡mara |\n",
    "| Interactividad | No | SÃ­ (presionar 'q' para salir) |\n",
    "| VisualizaciÃ³n | Guarda a archivo | `cv2.imshow()` en ventana |\n",
    "\n",
    "### Flujo de webcam\n",
    "\n",
    "```python\n",
    "while True:\n",
    "    frame = webcam.read()      # Capturar frame\n",
    "    annotated = process(frame) # Detectar + anotar\n",
    "    cv2.imshow(annotated)      # Mostrar en ventana\n",
    "    if key == 'q': break       # Salir si presiona 'q'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCIÃ“N DE DETECCIÃ“N EN WEBCAM\n",
    "# ============================================================\n",
    "\n",
    "def run_webcam_detection(duration_seconds: int = 30):\n",
    "    \"\"\"\n",
    "    Ejecuta detecciÃ³n YOLO en tiempo real usando la webcam.\n",
    "    \n",
    "    Args:\n",
    "        duration_seconds: DuraciÃ³n mÃ¡xima en segundos (default: 30)\n",
    "    \n",
    "    Controles:\n",
    "        - Presiona 'q' para salir antes de tiempo\n",
    "    \"\"\"\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # ABRIR WEBCAM\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    cap = cv2.VideoCapture(0)  # 0 = webcam por defecto\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Error: No se puede abrir la webcam\")\n",
    "        return\n",
    "    \n",
    "    # Obtener FPS de la webcam (tÃ­picamente 30)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    max_frames = int(duration_seconds * fps)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # INICIALIZAR TRACKER Y ANOTADORES\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    tracker = sv.ByteTrack()  # Nuevo tracker para esta sesiÃ³n\n",
    "    box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "    label_annotator = sv.LabelAnnotator(text_scale=0.5, text_thickness=1)\n",
    "    trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=50)\n",
    "    \n",
    "    print(f\"ğŸ¥ Iniciando detecciÃ³n en webcam\")\n",
    "    print(f\"   DuraciÃ³n mÃ¡xima: {duration_seconds}s\")\n",
    "    print(f\"   Presiona 'q' en la ventana para salir\\n\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # BUCLE PRINCIPAL\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    while frame_count < max_frames:\n",
    "        # Capturar frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"âš ï¸ Error leyendo frame\")\n",
    "            break\n",
    "        \n",
    "        # DetecciÃ³n\n",
    "        results = model(frame, conf=0.5, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        \n",
    "        # Tracking\n",
    "        detections = tracker.update_with_detections(detections)\n",
    "        \n",
    "        # Etiquetas con ID de tracking\n",
    "        if detections.tracker_id is not None:\n",
    "            labels = [\n",
    "                f\"#{tid} {model.names[cid]}\"\n",
    "                for tid, cid in zip(detections.tracker_id, detections.class_id)\n",
    "            ]\n",
    "        else:\n",
    "            labels = [model.names[cid] for cid in detections.class_id]\n",
    "        \n",
    "        # Anotar\n",
    "        annotated = frame.copy()\n",
    "        annotated = trace_annotator.annotate(annotated, detections)\n",
    "        annotated = box_annotator.annotate(annotated, detections)\n",
    "        annotated = label_annotator.annotate(annotated, detections, labels=labels)\n",
    "        \n",
    "        # Mostrar en ventana\n",
    "        cv2.imshow(\"YOLO Webcam - Presiona 'q' para salir\", annotated)\n",
    "        \n",
    "        # Verificar si se presionÃ³ 'q'\n",
    "        # cv2.waitKey(1) espera 1ms y devuelve la tecla presionada\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"\\nğŸ‘‹ Saliendo por peticiÃ³n del usuario\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # LIMPIAR RECURSOS\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    cap.release()              # Liberar webcam\n",
    "    cv2.destroyAllWindows()    # Cerrar ventanas\n",
    "    \n",
    "    print(f\"\\nâœ… DetecciÃ³n finalizada\")\n",
    "    print(f\"   Frames procesados: {frame_count}\")\n",
    "    print(f\"   DuraciÃ³n: {frame_count/fps:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EJECUTAR DETECCIÃ“N EN WEBCAM\n",
    "# ============================================================\n",
    "# Descomenta la siguiente lÃ­nea para ejecutar (30 segundos)\n",
    "\n",
    "# run_webcam_detection(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Resumen y Arquitectura\n",
    "\n",
    "### Pipeline Completo\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                           PIPELINE DE DETECCIÃ“N                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚   ENTRADA   â”‚      â”‚      YOLO       â”‚      â”‚  BYTETRACK  â”‚      â”‚ ANNOTATORS  â”‚\n",
    "  â”‚             â”‚      â”‚                 â”‚      â”‚             â”‚      â”‚             â”‚\n",
    "  â”‚ â€¢ Webcam    â”‚ â”€â”€â”€â–º â”‚ â€¢ Backbone CNN  â”‚ â”€â”€â”€â–º â”‚ â€¢ Kalman    â”‚ â”€â”€â”€â–º â”‚ â€¢ Box       â”‚\n",
    "  â”‚ â€¢ Video     â”‚      â”‚ â€¢ Neck FPN      â”‚      â”‚   Filter    â”‚      â”‚ â€¢ Label     â”‚\n",
    "  â”‚ â€¢ Imagen    â”‚      â”‚ â€¢ Head          â”‚      â”‚ â€¢ Hungarian â”‚      â”‚ â€¢ Trace     â”‚\n",
    "  â”‚             â”‚      â”‚                 â”‚      â”‚   Matching  â”‚      â”‚             â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚                      â”‚                      â”‚                    â”‚\n",
    "        â–¼                      â–¼                      â–¼                    â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚  np.array   â”‚      â”‚  sv.Detections  â”‚      â”‚ + tracker_  â”‚      â”‚   Frame     â”‚\n",
    "  â”‚  BGR        â”‚      â”‚  â€¢ xyxy         â”‚      â”‚   id        â”‚      â”‚  anotado    â”‚\n",
    "  â”‚  HxWx3      â”‚      â”‚  â€¢ confidence   â”‚      â”‚             â”‚      â”‚             â”‚\n",
    "  â”‚             â”‚      â”‚  â€¢ class_id     â”‚      â”‚             â”‚      â”‚             â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Clases y Funciones Principales\n",
    "\n",
    "| Componente | Clase/FunciÃ³n | DescripciÃ³n |\n",
    "|------------|---------------|-------------|\n",
    "| **Modelo** | `YOLO(\"yolo11n.pt\")` | Carga modelo pre-entrenado |\n",
    "| **Inferencia** | `model(frame)` | Ejecuta detecciÃ³n |\n",
    "| **Detecciones** | `sv.Detections.from_ultralytics()` | Convierte a formato unificado |\n",
    "| **Tracking** | `sv.ByteTrack()` | Crea tracker |\n",
    "| **Tracking** | `tracker.update_with_detections()` | Asigna IDs persistentes |\n",
    "| **AnotaciÃ³n** | `sv.BoxAnnotator()` | Dibuja rectÃ¡ngulos |\n",
    "| **AnotaciÃ³n** | `sv.LabelAnnotator()` | Dibuja etiquetas |\n",
    "| **AnotaciÃ³n** | `sv.TraceAnnotator()` | Dibuja trayectorias |\n",
    "| **Video** | `sv.process_video()` | Procesa video con callback |\n",
    "| **Video** | `sv.VideoInfo.from_video_path()` | Obtiene metadatos |\n",
    "\n",
    "### Atributos de sv.Detections\n",
    "\n",
    "| Atributo | Tipo | DescripciÃ³n |\n",
    "|----------|------|-------------|\n",
    "| `xyxy` | `np.array [N, 4]` | Bounding boxes [x1, y1, x2, y2] |\n",
    "| `confidence` | `np.array [N]` | Confianza de cada detecciÃ³n (0-1) |\n",
    "| `class_id` | `np.array [N]` | ID de clase (0-79 para COCO) |\n",
    "| `tracker_id` | `np.array [N]` | ID de tracking (None si no hay tracking) |\n",
    "| `mask` | `np.array [N, H, W]` | MÃ¡scaras de segmentaciÃ³n (opcional) |\n",
    "| `data` | `dict` | Datos adicionales personalizados |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Ejercicios Propuestos\n",
    "\n",
    "### Ejercicio 1: Filtrar por clase\n",
    "Modifica `process_frame()` para detectar solo personas:\n",
    "```python\n",
    "# Filtrar detecciones donde class_id == 0 (person en COCO)\n",
    "mask = detections.class_id == 0\n",
    "detections = detections[mask]\n",
    "```\n",
    "\n",
    "### Ejercicio 2: Contar objetos\n",
    "AÃ±ade un contador de objetos Ãºnicos usando los tracker_id:\n",
    "```python\n",
    "unique_ids = set()\n",
    "# En cada frame: unique_ids.update(detections.tracker_id)\n",
    "# Al final: print(f\"Objetos Ãºnicos: {len(unique_ids)}\")\n",
    "```\n",
    "\n",
    "### Ejercicio 3: Zona de conteo\n",
    "Cuenta cuÃ¡ntos objetos cruzan una lÃ­nea usando `sv.LineZone`:\n",
    "```python\n",
    "line = sv.LineZone(start=(0, 300), end=(640, 300))\n",
    "line.trigger(detections)  # Devuelve (in_count, out_count)\n",
    "```\n",
    "\n",
    "### Ejercicio 4: Guardar detecciones\n",
    "Exporta las detecciones a un archivo CSV o JSON para anÃ¡lisis posterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
